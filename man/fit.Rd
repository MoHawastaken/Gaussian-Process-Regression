% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit.R
\name{fit}
\alias{fit}
\title{Optimization of hyperparameters}
\usage{
\preformatted{fit(X, y, noise, cov_names)}
}
\arguments{
\item{X}{matrix of inputs}

\item{y}{numeric vector of targets}

\item{noise}{the inflicted noise of the observations}

\item{cov_names}{a list of names of covariance functions; if no list is given, all implemented functions are used
("sqrexp", "gammaexp", "constant", "linear", polynomial", "rationalquadratic")}
}
\value{
A list of outputs:
\describe{
  \item{$par}{The optimal parameters}
  \item{$cov}{The name of the optimal covariance function}
  \item{$score}{The scores for the different covariance functions in \code{cov_names}}
  \item{$func}{The optimal covariance function}
}
}
\description{
Applies optimization methods to find optimal parameters of given covariance functions for a given set of datapoints
}
\details{
\code{fit()} maximizes the log likelihood of the posterior distribution as a function of the hyperparameters.
Depending on the covariance function and the inflicted noise, the matrix K + noise * diag(n) - where K is the covariance matrix
of X - may be singular, so that the needed Cholesky decomposition is not posible. In this case \code{optim()} stops for the
actual covariance function and the best hyperparameters up that point are saved. This behaviour may be responsible for a bad fit,
especially with noise = 0 or small enough.
}
\examples{
X <- matrix(seq(-5, 5, by = 0.2), nrow = 1)
y <- c(0.15 * X^3 + rnorm(length(X), 0, 1))
fit(X, y, noise = 1, cov_names = list("linear","polynomial","sqrexp"))

z <- fit(X, y, noise = 1)
Gaussian <- GPR$new(X, y, noise = 1, z$func)
Gaussian$plot()$plot

}
\references{
Rasmussen, Carl E.; Williams, Christopher K. I. (2006).	Gaussian processes for machine learning
}
